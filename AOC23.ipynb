{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(Path().absolute(), \"inputs\", \"input23.txt\")\n",
    "# fp = os.path.join(Path().absolute(), \"inputs\", \"input23_test.txt\")\n",
    "\n",
    "with open(fp, \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(data)\n",
    "num_cols = len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPES = [\"<\", \">\", \"^\", \"v\"]\n",
    "ALLOWED = [\".\"] + SLOPES\n",
    "\n",
    "def get_neighbours(point, with_slopes=True):\n",
    "    x, y = point\n",
    "\n",
    "    if with_slopes and data[x][y] in SLOPES:\n",
    "        if data[x][y] == \"^\" and x > 0:\n",
    "            neighbours = [(x - 1, y)]\n",
    "        elif data[x][y] == \"v\" and x < num_rows - 1:\n",
    "            neighbours = [(x + 1, y)]\n",
    "        elif data[x][y] == \"<\" and y > 0:\n",
    "            neighbours = [(x, y - 1)]\n",
    "        elif data[x][y] == \">\" and y < num_cols - 1:\n",
    "            neighbours = [(x, y + 1)]\n",
    "\n",
    "    else:\n",
    "        neighbours = []\n",
    "        if x > 0:\n",
    "            cand = (x - 1, y)\n",
    "            if data[cand[0]][cand[1]] in ALLOWED:\n",
    "                neighbours.append(cand)\n",
    "        if x < num_rows - 1:\n",
    "            cand = (x + 1, y)\n",
    "            if data[cand[0]][cand[1]] in ALLOWED:\n",
    "                neighbours.append(cand)\n",
    "        if y > 0:\n",
    "            cand = (x, y - 1)\n",
    "            if data[cand[0]][cand[1]] in ALLOWED:\n",
    "                neighbours.append(cand)\n",
    "        if y < num_cols - 1:\n",
    "            cand = (x, y + 1)\n",
    "            if data[cand[0]][cand[1]] in ALLOWED:\n",
    "                neighbours.append(cand)\n",
    "\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = 0\n",
    "start_y = data[0].index(\".\")\n",
    "print(start_x, start_y)\n",
    "start = (start_x, start_y)\n",
    "\n",
    "end_x = num_rows - 1\n",
    "end_y = data[num_rows - 1].index(\".\")\n",
    "print(end_x, end_y)\n",
    "end = (end_x, end_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neighbours_dict(with_slopes):\n",
    "    neighbours_dict = {}\n",
    "    for x in range(num_rows):\n",
    "        for y in range(num_cols):\n",
    "            point = (x, y)\n",
    "            neighbours = get_neighbours(point, with_slopes=with_slopes)\n",
    "            neighbours_dict[point] = neighbours\n",
    "    \n",
    "    return neighbours_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_slopes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours_dict = build_neighbours_dict(with_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOO SLOW for part 2\n",
    "\n",
    "# exhaustive depth-first search\n",
    "current = start\n",
    "current_path = [start]\n",
    "forks = []\n",
    "\n",
    "\n",
    "# keep track of all forks encountered on current path along with children explored so far\n",
    "# e.g. [(p1, {p2: visited, p3: unvisited}, index_of_parent_in_path), ...]\n",
    "\n",
    "max_num_iter = 10000000\n",
    "num_iter = 0\n",
    "longest_path_length = -float(\"inf\")\n",
    "\n",
    "num_paths_explored = 0\n",
    "\n",
    "while num_iter < max_num_iter:\n",
    "    # print(f\"{num_iter = }\")\n",
    "    # print(current_path)\n",
    "\n",
    "    if num_iter % 1000 == 0:\n",
    "        print(num_iter, num_paths_explored)\n",
    "\n",
    "    if current == end:\n",
    "        at_end = True\n",
    "        if len(current_path) > longest_path_length:\n",
    "            longest_path_length = len(current_path)\n",
    "            print(f\"new {longest_path_length = }\")\n",
    "    else:\n",
    "        at_end = False\n",
    "\n",
    "    neighbours = neighbours_dict[current]\n",
    "    neighbours_excl_repetitions = [n for n in neighbours if n not in current_path]\n",
    "    # if len([n for n in neighbours if n in current_path[:-2]]) > 0:\n",
    "    #     print(\"cyclic\", current_path)\n",
    "    if len(neighbours_excl_repetitions) == 0 or at_end:\n",
    "\n",
    "        # if len(neighbours_excl_repetitions) == 0:\n",
    "        #     print(\"No more neighbours\", current)\n",
    "\n",
    "        num_paths_explored += 1\n",
    "\n",
    "        # backtrack\n",
    "        last_fork_index_old = last_fork_index\n",
    "        \n",
    "        search_terminated = True\n",
    "        for fork_index in range(last_fork_index, -1, -1):\n",
    "            unvisited_children = [ch for ch, visited_status in forks[fork_index][1].items() if visited_status is False]\n",
    "            if len(unvisited_children) > 0:\n",
    "                current = unvisited_children[0]\n",
    "                last_fork_index = fork_index\n",
    "                current_path = current_path[:(forks[last_fork_index][2] + 1)] + [current]\n",
    "                forks = forks[:(last_fork_index + 1)]\n",
    "                forks[last_fork_index][1][current] = True\n",
    "                search_terminated = False\n",
    "                break\n",
    "        \n",
    "        # if last_fork_index <= 10:\n",
    "        # print(f\"backtracking to last_fork_index {last_fork_index} / {last_fork_index_old}\")\n",
    "        if search_terminated:\n",
    "            break\n",
    "\n",
    "    elif len(neighbours_excl_repetitions) == 1:\n",
    "        current = neighbours_excl_repetitions[0]\n",
    "        current_path.append(current)\n",
    "\n",
    "    elif len(neighbours_excl_repetitions) > 1:\n",
    "        new_fork = (current, {n: False for n in neighbours_excl_repetitions}, len(current_path) - 1)\n",
    "\n",
    "        current = neighbours_excl_repetitions[0]\n",
    "        new_fork[1][current] = True\n",
    "        forks.append(new_fork)\n",
    "        last_fork_index = len(forks) - 1\n",
    "        \n",
    "        current_path.append(current)\n",
    "\n",
    "        # print(f\"Adding new fork: {forks = }\")\n",
    "\n",
    "\n",
    "    num_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_path_length - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all forks to make the subsequent depth-first search faster (each node will be a fork), i.e. do edge contraction. Otherwise DFS will be too slow if it operates on all cells (even if they're not forks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_slopes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_dict(with_slopes):\n",
    "\n",
    "    adj_dict = {}\n",
    "\n",
    "    for x in range(num_rows):\n",
    "        for y in range(num_cols):\n",
    "            point = (x, y)\n",
    "            if data[x][y] != \"#\" or point in [start, end]:\n",
    "                neighbours = get_neighbours(point, with_slopes=with_slopes)\n",
    "                if len(neighbours) > 2 or point in [start, end]:\n",
    "                    # this is a fork (or start or end)\n",
    "                    # follow to next fork\n",
    "                    start_fork = point\n",
    "                    adj_dict[start_fork] = {}\n",
    "                    for neighbour in neighbours:\n",
    "                        current = neighbour\n",
    "                        current_path = [start_fork, current]\n",
    "\n",
    "                        while True:\n",
    "                            neighbours = get_neighbours(current, with_slopes=with_slopes)\n",
    "                            neighbours_excl_prev = [n for n in neighbours if n != current_path[-2]]\n",
    "                            if len(neighbours_excl_prev) == 1:\n",
    "                                current = neighbours_excl_prev[0]\n",
    "                                current_path.append(current)\n",
    "                            elif len(neighbours_excl_prev) >= 2:\n",
    "                                # encountered fork\n",
    "                                end_point = current\n",
    "                                # current_path.append(current)\n",
    "                                break\n",
    "                            elif current in [start, end]:\n",
    "                                end_point = current\n",
    "                                # current_path.append(current)\n",
    "                                break\n",
    "                            else:\n",
    "                                raise ValueError(\"cul-de-sac found\")\n",
    "\n",
    "                        adj_dict[start_fork][end_point] = len(current_path) - 1\n",
    "\n",
    "    return adj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dict = build_adj_dict(with_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_forks = 0\n",
    "for x in range(num_rows):\n",
    "    for y in range(num_cols):\n",
    "        if data[x][y] != \"#\":\n",
    "            n = get_neighbours((x, y), with_slopes=False)\n",
    "            if len(n) > 2:\n",
    "                # print(len(n))\n",
    "                num_forks += 1\n",
    "                # print((x, y), n)\n",
    "\n",
    "print(num_forks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fork, neighbouring_forks in adj_dict.items():\n",
    "    for neighbouring_fork, dist in neighbouring_forks.items():\n",
    "        assert fork in adj_dict[neighbouring_fork] and adj_dict[neighbouring_fork][fork] == dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is a bit slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_dfs_over_forks(adj_dict, start, end):\n",
    "\n",
    "    # exhaustive depth-first search\n",
    "    current = start\n",
    "    current_path = [start]\n",
    "    forks = []\n",
    "\n",
    "    # keep track of all forks encountered on current path along with children explored so far\n",
    "    # e.g. [(p1, {p2: visited, p3: unvisited}, index_of_parent_in_path, path_length_so_far), ...]\n",
    "\n",
    "    max_num_iter = 1000000000\n",
    "    num_iter = 0\n",
    "    longest_path_length = -float(\"inf\")\n",
    "    current_path_length = 0\n",
    "\n",
    "    longest_path = None\n",
    "\n",
    "    num_paths_explored = 0\n",
    "\n",
    "    while num_iter < max_num_iter:\n",
    "        # print(f\"{num_iter = }\")\n",
    "        # print(current_path)\n",
    "\n",
    "        if num_iter % 100000 == 0:\n",
    "            print(num_iter, num_paths_explored)\n",
    "\n",
    "        if current == end:\n",
    "            at_end = True\n",
    "            if current_path_length > longest_path_length:\n",
    "                longest_path_length = current_path_length\n",
    "                print(f\"new {longest_path_length = }\")\n",
    "                longest_path = copy.deepcopy(current_path)\n",
    "        else:\n",
    "            at_end = False\n",
    "\n",
    "        neighbours = adj_dict[current]\n",
    "        neighbours_excl_repetitions = [n for n in neighbours if n not in current_path]\n",
    "        if len(neighbours_excl_repetitions) == 0 or at_end:\n",
    "\n",
    "            num_paths_explored += 1\n",
    "\n",
    "            # backtrack\n",
    "            last_fork_index_old = last_fork_index\n",
    "            \n",
    "            search_terminated = True\n",
    "            for fork_index in range(last_fork_index, -1, -1):\n",
    "                prev_fork = forks[fork_index]\n",
    "                prev_fork_parent = prev_fork[0]\n",
    "                unvisited_children = [ch for ch, visited_status in prev_fork[1].items() if visited_status is False]\n",
    "                if len(unvisited_children) > 0:\n",
    "                    current = unvisited_children[0]\n",
    "                    last_fork_index = fork_index\n",
    "\n",
    "                    dist_last_fork_to_child = adj_dict[prev_fork_parent][current]\n",
    "                    current_path_length = forks[last_fork_index][3] + dist_last_fork_to_child\n",
    "\n",
    "                    current_path = current_path[:(forks[last_fork_index][2] + 1)] + [current]\n",
    "                    forks = forks[:(last_fork_index + 1)]\n",
    "                    forks[last_fork_index][1][current] = True\n",
    "                    search_terminated = False\n",
    "                    break\n",
    "            \n",
    "            if last_fork_index <= 5:\n",
    "                print(f\"backtracking to last_fork_index {last_fork_index} / {last_fork_index_old}\")\n",
    "            if search_terminated:\n",
    "                break\n",
    "\n",
    "        elif len(neighbours_excl_repetitions) == 1:\n",
    "            next_neighbour = neighbours_excl_repetitions[0]\n",
    "            dist = adj_dict[current][next_neighbour]\n",
    "            current = next_neighbour\n",
    "            current_path.append(current)\n",
    "            current_path_length += dist\n",
    "\n",
    "        elif len(neighbours_excl_repetitions) > 1:\n",
    "            new_fork = (current, {n: False for n in neighbours_excl_repetitions}, len(current_path) - 1, current_path_length)\n",
    "            next_neighbour = neighbours_excl_repetitions[0]\n",
    "            dist = adj_dict[current][next_neighbour]\n",
    "\n",
    "            current = next_neighbour\n",
    "            new_fork[1][current] = True\n",
    "            forks.append(new_fork)\n",
    "            last_fork_index = len(forks) - 1\n",
    "            \n",
    "            current_path.append(current)\n",
    "            current_path_length += dist\n",
    "\n",
    "            # print(f\"Adding new fork: {forks = }\")\n",
    "\n",
    "        num_iter += 1\n",
    "\n",
    "    return longest_path, longest_path_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_path, longest_path_length = do_dfs_over_forks(adj_dict, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(longest_path) == len(set(longest_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_path[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_path_length # NOT off by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "total = 0\n",
    "for i in range(len(longest_path) - 1):\n",
    "    total += adj_dict[longest_path[i]][longest_path[i + 1]]\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a recursion is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dict_alt = {k: list(v.items()) for k, v in adj_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_dfs_recursive(adj_dict_alt, start, end, seen=set()):\n",
    "\n",
    "    if start == end:\n",
    "        return [0]\n",
    "    \n",
    "    seen.add(start)\n",
    "    path_lengths = []\n",
    "\n",
    "    for next_vertex, dist in adj_dict_alt[start]:\n",
    "        if next_vertex not in seen:\n",
    "            res = do_dfs_recursive(adj_dict_alt, next_vertex, end, seen)\n",
    "            for pl in res:\n",
    "                path_lengths.append(pl + dist)\n",
    "\n",
    "    seen.remove(start)\n",
    "\n",
    "    return path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lengths = do_dfs_recursive(adj_dict_alt, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(path_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
