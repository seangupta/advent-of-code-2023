{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from itertools import combinations, product\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(Path().absolute(), \"inputs\", \"input19.txt\")\n",
    "# fp = os.path.join(Path().absolute(), \"inputs\", \"input19_test.txt\")\n",
    "\n",
    "with open(fp, \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = data.index(\"\")\n",
    "workflows = data[:sep]\n",
    "parts = data[(sep + 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_list = []\n",
    "for line in parts:\n",
    "    line_elts = line[1:-1].split(\",\")\n",
    "    part = {}\n",
    "    for line_elt in line_elts:\n",
    "        attr, value = line_elt.split(\"=\")\n",
    "        part[attr] = int(value)\n",
    "    parts_list.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_dict = {}\n",
    "for line in workflows:\n",
    "    name, rest = line.split(\"{\")\n",
    "    rest = rest[:-1]\n",
    "    instructions = []\n",
    "    rest_elts = rest.split(\",\")\n",
    "    for rest_elt in rest_elts:\n",
    "        if \":\" in rest_elt:\n",
    "            condition, dest = rest_elt.split(\":\")\n",
    "        else:\n",
    "            condition = \"True\"\n",
    "            dest = rest_elt\n",
    "        \n",
    "        instruction = [condition, dest]\n",
    "        instructions.append(instruction)\n",
    "\n",
    "    workflow_dict[name] = instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_parts = []\n",
    "\n",
    "total = 0\n",
    "for part in parts_list:\n",
    "    x = part[\"x\"]\n",
    "    m = part[\"m\"]\n",
    "    a = part[\"a\"]\n",
    "    s = part[\"s\"]\n",
    "\n",
    "    current_workflow_name = \"in\"\n",
    "    instruction_idx = 0\n",
    "    terminated = False\n",
    "    \n",
    "    while not terminated:\n",
    "        instructions = workflow_dict[current_workflow_name]\n",
    "        condition, dest = instructions[instruction_idx]\n",
    "        # print(part, condition, dest)\n",
    "        if eval(condition):\n",
    "            if dest == \"A\":\n",
    "                accepted_parts.append(part)\n",
    "                terminated = True\n",
    "            elif dest == \"R\":\n",
    "                terminated = True\n",
    "            else:\n",
    "                current_workflow_name = dest\n",
    "            instruction_idx = 0\n",
    "        else:\n",
    "            instruction_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(sum(part.values()) for part in accepted_parts)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a graph of all nodes. The accept node will accept the Cartesian product of all ranges 1 <= {x, m, a, s} <= 4000. The reject node will accept the empty set. \n",
    "\n",
    "We then propagate up the accept ranges using interval calculus. We can always find a node whose children's accept areas we already know (proof by induction). We then combine the children's accept areas with the node conditions to compute the node's accept area.\n",
    "\n",
    "Note that this solution, while slow, works for any DAG (not just a tree structure, in which case we could usa recursion starting from the root node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    ratings = [\"x\", \"m\", \"a\", \"s\"]\n",
    "\n",
    "    def __init__(self, name, condition=None):\n",
    "        self.name = name\n",
    "        self.condition = condition\n",
    "        self.true_parents = []\n",
    "        self.false_parents = []\n",
    "        self.true_child = None\n",
    "        self.false_child = None\n",
    "        self.accept_area = None # everything outside is rejected\n",
    "\n",
    "    def add_child(self, node, edge):\n",
    "        assert isinstance(node, Node)\n",
    "        assert edge in [\"T\", \"F\"]\n",
    "\n",
    "        if edge == \"T\":\n",
    "            self.true_child = node\n",
    "            node.true_parents.append(self)\n",
    "        else:\n",
    "            self.false_child = node\n",
    "            node.false_parents.append(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_node = Node(\"R\", None)\n",
    "accept_node = Node(\"A\", None)\n",
    "all_nodes = {\"R\": reject_node, \"A\": accept_node}\n",
    "\n",
    "for prefix, instructions in workflow_dict.items():\n",
    "    num_elts = len(instructions)\n",
    "\n",
    "    for instruction_idx, instruction in enumerate(instructions[:-1]):\n",
    "        cond, dest = instruction\n",
    "\n",
    "        current_name = prefix + str(instruction_idx)\n",
    "        if current_name in all_nodes:\n",
    "            current_node = all_nodes[current_name]\n",
    "            if current_node.condition is None:\n",
    "                assert \"<\" in cond or \">\" in cond or \"=\" in cond\n",
    "                current_node.condition = cond\n",
    "        else:\n",
    "            current_node = Node(current_name, cond)\n",
    "            all_nodes[current_name] = current_node\n",
    "        \n",
    "        # Add true child node\n",
    "        if dest in [\"R\", \"A\"]:\n",
    "            true_child_name = dest\n",
    "        else:\n",
    "            true_child_name = dest + \"0\"\n",
    "        if true_child_name in all_nodes:\n",
    "            true_child_node = all_nodes[true_child_name]\n",
    "        else:\n",
    "            true_child_node = Node(true_child_name)\n",
    "            all_nodes[true_child_name] = true_child_node\n",
    "        current_node.add_child(true_child_node, \"T\")\n",
    "\n",
    "        # Add false child node\n",
    "        if instruction_idx == num_elts - 2:\n",
    "            # Penultimate instruction\n",
    "            next_instruction = instructions[instruction_idx + 1]\n",
    "            next_instruction_cond, next_instruction_dest = next_instruction\n",
    "            assert next_instruction_cond == \"True\"\n",
    "            if next_instruction_dest in [\"R\", \"A\"]:\n",
    "                false_child_name = next_instruction_dest\n",
    "            else:\n",
    "                false_child_name = next_instruction_dest + \"0\"\n",
    "        else:\n",
    "            false_child_name = prefix + str(instruction_idx + 1)\n",
    "    \n",
    "        if false_child_name in all_nodes:\n",
    "            false_child_node = all_nodes[false_child_name]\n",
    "        else:\n",
    "            false_child_node = Node(false_child_name)\n",
    "            all_nodes[false_child_name] = false_child_node\n",
    "        current_node.add_child(false_child_node, \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, node in all_nodes.items():\n",
    "    print(name, node.condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptySet:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class Interval:\n",
    "\n",
    "    def __init__(self, left, right):\n",
    "        assert 1 <= left <= right <= 4000\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def compute_length(self):\n",
    "        return self.right - self.left + 1\n",
    "    \n",
    "    def intersect(self, interval):\n",
    "        assert isinstance(interval, Interval)\n",
    "        intersection_left = max(self.left, interval.left)\n",
    "        intersection_right = min(self.right, interval.right)\n",
    "        if intersection_left <= intersection_right:\n",
    "            return Interval(intersection_left, intersection_right)\n",
    "        else:\n",
    "            return EmptySet()\n",
    "        \n",
    "    def complement(self):\n",
    "        intervals = []\n",
    "        if self.left >= 2:\n",
    "            interval = Interval(1, self.left - 1)\n",
    "            intervals.append(interval)\n",
    "        if self.right <= 3999:\n",
    "            interval = Interval(self.right + 1, 4000)\n",
    "            intervals.append(interval)\n",
    "\n",
    "        interval_collection = IntervalCollection(intervals)\n",
    "        return interval_collection\n",
    "    \n",
    "    def union(self, interval):\n",
    "        assert isinstance(interval, Interval)\n",
    "        intersection = self.intersect(interval)\n",
    "        if not isinstance(intersection, EmptySet):\n",
    "            union_left = min(self.left, interval.left)\n",
    "            union_right = max(self.right, interval.right)\n",
    "            return Interval(union_left, union_right)\n",
    "        elif self.right + 1 == interval.left:\n",
    "            union_left = self.left\n",
    "            union_right = interval.right\n",
    "            return Interval(union_left, union_right)\n",
    "        elif interval.right + 1 == self.left:\n",
    "            union_left = interval.left\n",
    "            union_right = self.right\n",
    "            return Interval(union_left, union_right)\n",
    "        else:\n",
    "            return IntervalCollection([self, interval])\n",
    "    \n",
    "class IntervalCollection:\n",
    "    \"\"\"Disjoint union of Intervals\"\"\"\n",
    "\n",
    "    def __init__(self, intervals):\n",
    "        assert isinstance(intervals, list)\n",
    "        for interval in intervals:\n",
    "            assert isinstance(interval, Interval)\n",
    "\n",
    "        self.intervals = intervals\n",
    "    \n",
    "class AreaPart:\n",
    "    \"\"\"Cartesian product of Intervals\"\"\"\n",
    "\n",
    "    def __init__(self, x_interval, m_interval, a_interval, s_interval):\n",
    "        assert isinstance(x_interval, Interval)\n",
    "        assert isinstance(m_interval, Interval)\n",
    "        assert isinstance(a_interval, Interval)\n",
    "        assert isinstance(s_interval, Interval)\n",
    "\n",
    "        self.d = {\"x\": x_interval, \"m\": m_interval, \"a\": a_interval, \"s\": s_interval}\n",
    "\n",
    "    def compute_size(self):\n",
    "        prod = 1\n",
    "        for rating in Node.ratings:\n",
    "            interval_length = self.d[rating].compute_length()\n",
    "            assert interval_length >= 1\n",
    "            prod *= interval_length\n",
    "        \n",
    "        return prod\n",
    "    \n",
    "    def intersect(self, area_part):\n",
    "        assert isinstance(area_part, AreaPart)\n",
    "\n",
    "        x_interval_intersection = self.d[\"x\"].intersect(area_part.d[\"x\"])\n",
    "        m_interval_intersection = self.d[\"m\"].intersect(area_part.d[\"m\"])\n",
    "        a_interval_intersection = self.d[\"a\"].intersect(area_part.d[\"a\"])\n",
    "        s_interval_intersection = self.d[\"s\"].intersect(area_part.d[\"s\"])\n",
    "\n",
    "        if any(isinstance(intersection, EmptySet) for intersection in [x_interval_intersection, m_interval_intersection, a_interval_intersection, s_interval_intersection]):\n",
    "            return EmptySet()\n",
    "\n",
    "        return AreaPart(x_interval_intersection, m_interval_intersection, a_interval_intersection, s_interval_intersection)\n",
    "    \n",
    "    def complement(self):\n",
    "\n",
    "        # # Negate at least one rating\n",
    "        # for r in range(1, 5):\n",
    "        #     combs = list(combinations(Node.ratings, r))\n",
    "        #     # negate all ratings in comb\n",
    "        #     for comb in combs:\n",
    "        #         list_of_interval_collections = []\n",
    "        #         for rating in Node.ratings:\n",
    "        #             if rating in comb:\n",
    "        #                 # negate\n",
    "        #                 complement = self.d[rating].complement()\n",
    "        #                 assert isinstance(complement, IntervalCollection)\n",
    "        #                 list_of_interval_collections.append(complement)\n",
    "        #             else:\n",
    "        #                 list_of_interval_collections.append(IntervalCollection(self.d[rating]))\n",
    "                \n",
    "        #         # Each element of the Cartesian product is an AreaPart\n",
    "        #         area_parts_this_comb = [AreaPart(*seq) for seq in list(product(list_of_interval_collections))]\n",
    "        #         area_parts.append(area_parts_this_comb)\n",
    "\n",
    "\n",
    "        # More compact\n",
    "        area_list = []\n",
    "        for idx_to_negate in range(4):\n",
    "            \n",
    "            list_of_interval_collections = []\n",
    "            for i, rating in enumerate(Node.ratings):\n",
    "                if i < idx_to_negate:\n",
    "                    interval_collection = IntervalCollection([self.d[rating]])\n",
    "                elif i == idx_to_negate:\n",
    "                    interval_collection = self.d[rating].complement()\n",
    "                else:\n",
    "                    interval_collection = IntervalCollection([Interval(1, 4000)])\n",
    "\n",
    "                assert isinstance(interval_collection, IntervalCollection)\n",
    "                list_of_interval_collections.append(interval_collection.intervals)\n",
    "            \n",
    "            # Each element of the Cartesian product is an AreaPart\n",
    "            if not any(len(ic) == 0 for ic in list_of_interval_collections):\n",
    "                area = Area([AreaPart(*seq) for seq in product(*list_of_interval_collections)])\n",
    "                area_list.append(area)\n",
    "\n",
    "        # Disjoint union\n",
    "        res = Area([area_part for area in area_list for area_part in area.area_parts])\n",
    "\n",
    "        assert isinstance(res, Area)\n",
    "        return res\n",
    "    \n",
    "class Area:\n",
    "    \"\"\"Disjoint union of AreaParts\"\"\"\n",
    "\n",
    "    def __init__(self, area_parts):\n",
    "        assert isinstance(area_parts, list)\n",
    "        for area_part in area_parts:\n",
    "            assert isinstance(area_part, AreaPart)\n",
    "\n",
    "        self.area_parts = area_parts\n",
    "        \n",
    "        print(f\"Start of compactification, {len(area_parts) = }\")\n",
    "        self.compactify()\n",
    "        print(\"End of compactification\")\n",
    "\n",
    "    def compute_size(self):\n",
    "        \"\"\"Assumes that area parts are not overlapping\"\"\"\n",
    "        total = 0\n",
    "        for area_part in self.area_parts:\n",
    "            size = area_part.compute_size()\n",
    "            total += size\n",
    "\n",
    "        return total\n",
    "    \n",
    "    def intersect(self, area):\n",
    "        assert isinstance(area, Area)\n",
    "\n",
    "        area_parts_intersection = []\n",
    "        for area_part in self.area_parts:\n",
    "            for area_part_other_area in area.area_parts:\n",
    "                intersection = area_part.intersect(area_part_other_area)\n",
    "                if not isinstance(intersection, EmptySet):\n",
    "                    area_parts_intersection.append(intersection)\n",
    "\n",
    "        return Area(area_parts_intersection)\n",
    "    \n",
    "    def complement(self):\n",
    "\n",
    "        res = S\n",
    "        for area_part in self.area_parts:\n",
    "            cp = area_part.complement()\n",
    "            if isinstance(cp, EmptySet):\n",
    "                return EmptySet\n",
    "\n",
    "            assert isinstance(cp, Area)\n",
    "            res = res.intersect(cp)\n",
    "            if isinstance(cp, EmptySet):\n",
    "                return EmptySet\n",
    "\n",
    "            assert isinstance(res, Area)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def union(self, area):\n",
    "        assert isinstance(area, Area)\n",
    "\n",
    "        cp = self.complement()\n",
    "        print(\"Computed complement\")\n",
    "        \n",
    "        tmp_list = [self]\n",
    "        for other_area_part in area.area_parts:\n",
    "            tmp = cp.intersect(Area([other_area_part]))\n",
    "            tmp_list.append(tmp)\n",
    "\n",
    "        print(\"Computed tmp_list\")\n",
    "        # disjoint union of areas\n",
    "        res = Area([area_part for tmp in tmp_list for area_part in tmp.area_parts])\n",
    "        print(\"Computed res\")\n",
    "\n",
    "        assert isinstance(res, Area)\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def compactify(self):\n",
    "        \"\"\"Ensures that an area is represented in the most compact form possible\"\"\"\n",
    "\n",
    "        found_comb_list = []\n",
    "        combined_area_parts = []\n",
    "\n",
    "        for comb in combinations(enumerate(self.area_parts), 2):\n",
    "            (i, area_part1), (j, area_part2) = comb\n",
    "            if i in found_comb_list or j in found_comb_list:\n",
    "                continue\n",
    "\n",
    "            equal_ratings = []\n",
    "            for rating in Node.ratings:\n",
    "                if area_part1.d[rating].left == area_part2.d[rating].left and area_part1.d[rating].right == area_part2.d[rating].right:\n",
    "                    equal_ratings.append(rating)\n",
    "            if len(equal_ratings) == 4:\n",
    "                raise ValueError\n",
    "            elif len(equal_ratings) == 3:\n",
    "                differing_rating = [rating for rating in Node.ratings if rating not in equal_ratings][0]\n",
    "                interval_union = area_part1.d[differing_rating].union(area_part2.d[differing_rating])\n",
    "                if isinstance(interval_union, Interval):\n",
    "                    # Can combine\n",
    "                    d_new = copy.deepcopy(area_part1.d)\n",
    "                    d_new[differing_rating] = interval_union\n",
    "                    area_part_combined = AreaPart(x_interval=d_new[\"x\"], m_interval=d_new[\"m\"], a_interval=d_new[\"a\"], s_interval=d_new[\"s\"]) \n",
    "                    combined_area_parts.append(area_part_combined)\n",
    "                    found_comb_list += [i, j]\n",
    "\n",
    "        self.area_parts = [area_part for idx, area_part in enumerate(self.area_parts) if idx not in found_comb_list] + combined_area_parts\n",
    "        if len(found_comb_list) > 0:\n",
    "            self.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Area([AreaPart(Interval(1, 4000), Interval(1, 4000), Interval(1, 4000), Interval(1, 4000))])\n",
    "E = Area([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = Area([AreaPart(Interval(3, 4000), Interval(1, 4000), Interval(1, 4000), Interval(1, 4000)),\n",
    "          AreaPart(Interval(1, 2), Interval(1, 4000), Interval(1, 4000), Interval(1, 4000))])\n",
    "print(A1.area_parts)\n",
    "A1.compactify()\n",
    "print(A1.area_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_node.accept_area = E\n",
    "accept_node.accept_area = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_condition_to_accept_area(condition):\n",
    "    \"\"\"condition is of the form \n",
    "    x<2000 (or =, >)\n",
    "    \"\"\"\n",
    "    if \"<\" in condition:\n",
    "        rating, value = condition.split(\"<\")\n",
    "        value = int(value)\n",
    "        tmp = {}\n",
    "        for r in Node.ratings:\n",
    "            if r == rating:\n",
    "                tmp[r] = Interval(1, value - 1)\n",
    "            else:\n",
    "                tmp[r] = Interval(1, 4000)\n",
    "    \n",
    "    elif \">\" in condition:\n",
    "        rating, value = condition.split(\">\")\n",
    "        value = int(value)\n",
    "        tmp = {}\n",
    "        for r in Node.ratings:\n",
    "            if r == rating:\n",
    "                tmp[r] = Interval(value + 1, 4000)\n",
    "            else:\n",
    "                tmp[r] = Interval(1, 4000)\n",
    "\n",
    "    elif \"=\" in condition:\n",
    "        rating, value = condition.split(\"=\")\n",
    "        value = int(value)\n",
    "        tmp = {}\n",
    "        for r in Node.ratings:\n",
    "            if r == rating:\n",
    "                tmp[r] = Interval(value, value)\n",
    "            else:\n",
    "                tmp[r] = Interval(1, 4000)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown comparison operator\")\n",
    "\n",
    "    d = AreaPart(x_interval=tmp[\"x\"], m_interval=tmp[\"m\"], a_interval=tmp[\"a\"], s_interval=tmp[\"s\"]) \n",
    "    accept_area = Area([d])\n",
    "\n",
    "    return accept_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(all_nodes)\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_nodes = [reject_node, accept_node]\n",
    "\n",
    "while len(processed_nodes) < num_nodes:\n",
    "    # print(processed_nodes)\n",
    "    print(f\"Number of processed nodes = {len(processed_nodes)}\")\n",
    "    \n",
    "    # Find node whose children are all processed already\n",
    "    current_node = None\n",
    "    for name, node in all_nodes.items():\n",
    "        if node not in processed_nodes and node.true_child in processed_nodes and node.false_child in processed_nodes:\n",
    "            current_node = node\n",
    "            break\n",
    "    assert current_node is not None\n",
    "\n",
    "    # Compute accepted / rejected areas for current_node\n",
    "    A_true = node.true_child.accept_area\n",
    "    A_false = node.false_child.accept_area\n",
    "    A_condition = convert_condition_to_accept_area(node.condition)\n",
    "\n",
    "    print(f\"Computing tmp1\")\n",
    "    tmp1 = A_true.intersect(A_condition)\n",
    "    assert isinstance(tmp1, Area)\n",
    "\n",
    "    print(f\"Computing tmp2\")\n",
    "    tmp2 = A_condition.complement()\n",
    "    assert isinstance(tmp2, Area)\n",
    "\n",
    "    print(f\"Computing tmp3\")\n",
    "    tmp3 = A_false.intersect(tmp2)\n",
    "    assert isinstance(tmp3, Area)\n",
    "\n",
    "    print(f\"Computing accept area: {len(tmp1.area_parts) = }, {len(tmp3.area_parts) = }\")\n",
    "    accept_area = tmp1.union(tmp3)\n",
    "    assert isinstance(accept_area, Area)\n",
    "    current_node.accept_area = accept_area\n",
    "    print(\"Done processing node\")\n",
    "\n",
    "    processed_nodes.append(current_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of elements of root node accept area\n",
    "num_combs = all_nodes[\"in0\"].accept_area.compute_size()\n",
    "num_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
